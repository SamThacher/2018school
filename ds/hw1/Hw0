1) I am an undergraduate.
2) I took algorithms for NLP with Prof. Schneider last year and I have really liked the parts of the computational linguistics field that I am familiar with thus far. I think the intersection of computing and lingustics presents lots of unique and interesting challenges.
3) I have ~4 years of programming experience. The top 5 languages I am most comfortable with are probably python, ruby, c++, java, and javascript.
4) I have pretty strong experience with git and using git in software development settings. I am less comfortable with svn but I have used it before.
5) I have developed NLP software for the class I mentioned before with Prof. Schneider. In that class, we did n-grams, bayesian probability models, perceptron learning, hidden markov models, and some other work. For my final project, I made an extractive summary machine using sentence ranking algorithms.
6) Sure. That would be fun.
7) As someone new to the field I don't have anything to add here. But what's already there looks really interesting.


Chatbot comparison: Mitsuku is a much better chatbot than Cleverbot. Cleverbot got confused so quickly that it made regular conversation impossible. In other non-recorded conversations the cleverbot was prone to insults and other strange phrases. This is likely a symptom of its open-source nature... it is not very regulated for responses. The website even warns you to be careful as they don't necessarily know what it will say. This is also a reflection of a more abstracted AI-based approach. On the other hand, Mitsuku seems to be less automatically generated. One article describes its intelligence as "Her intelligence includes the ability to reason with specific objects. For example, if someone says "Can you eat a house?", Mitsuku looks up the properties for "house". Finds the value of "made_from" is set to "brick" and replies no, as a house is not edible." In this sense, Mitsuku is sort of created for a different purpose - to narrowly mimic human conversation rather than to see what kind of dialogue agent is created by talking a lot, like cleverbot is. So perhaps it is unfair to compare them since, in part, they serve different purposes.



Cleverbot review: (chat bot)
1)Name of the system: Cleverbot
2)How the system was accessed (e.g., web, smartphone, etc.): webapp
3)Recordings of all conversations that were analyzed (e.g., a text chat log, screenshots of the interactions, or audio-video recording with at least 10 turns of dialogue transcribed): see attached file cleverbot_chat.txt
4)Your overall rating of the system (1 = unusable, 7 = nearly perfect): 2
5)Explain your rating. Why did system perform well / badly? The system almost immediately lost the thread of the conversation, telling me I was repeating myself upon my second comment despite this not being the case.
6)How did the system follow or violate principles of human conversation? Cite specific principles (e.g., Turn-taking, Grounding, Conversational Structure, Gricean Maxims) and use specific turns from your conversations. The system violated Grounding by immediately thinking I was repeating myself when I wasn't - the grounding of the conversation is what is supposed to tell the system what has been said. This is in the 4th line when it says "You just said that". The system also called me a 'memory-less fowl' which I am not sure violates any direct principles but was definitely a non sequitur.
7)Best points about working with the system: Getting called a 'memory-less fowl'
8)Worst points about working with the system. What errors were you most surprised by? The system was very easily confused and the system makes it very difficult to try and have a conversation.
9)Would you use this system again (in the right domain) if you had a choice?: Not really... it seems to be somewhat primitive and uninteresting. 

Mitsuku review: (chat bot)
1) Mitsuku
2) webapp
3) 5
4) see attached file mitsuku_chat.txt
5) The system performed pretty well - it was able to take basic conversational cues and talk to me. I just tried to make basic small talk and in most situations it was able to follow. I provided a sample that is somewhat self-contained - it is not the only conversation I had with the system. 
6) It violated conversational structure in that it didn't understand the idea of a two part joke (ie one that has a question, a what, and an answer). Besides that, from most standpoints it did a decent job of introducing and carrying on the conversation in a normal way.
7) Having it tell a joke! I supposed that is a pretty common scenario for a chatbox since they don't really do actionable stuff but it was still fun. 
8) I wasn't particularly surprised that the bot dropped the thread on the joke but it would've been cool if it could've understood the structure of a two-line joke.
9) Sure. It was interesting and did a decent job. 

Watson Assistant review (assistant)
1) Watson Assistant
2) webapp
3) see attached file watsonassistant_chat.txt
4) 4
5) The system performed decently but was hamstrung by its highly restricted grammar. The system provided some sample commands but it was often unclear whether it was offering the whole set of commands or whether that was just some of them. 
6) It violated principles of conversational structure in that its canned response didn't even attempt conversation. It just repeated a response over and over. This doesn't allow it to participate it in coversation structure at all.
7) Listening to music. Also it was pretty good at finding gas stations - when I asked for them they appeared on the dashboard computer in a little map which was cool. 
8) I was surprised about how low effort and terrible the canned response was when the system didn't understand. It was absolutely terrible - it doesn't even differentiate between misunderstanding a response and being unable to get a response due to lack of connectivity. The assistant could at least ping the system and see if it was there before differentiating between the two types of failures.
9) Sure. It was decent and mainly lacked a decent error handling system.

Sgt Star review (website navigator)
1) Sgt Star
2) webapp
3) see attached file sgtstr_chat.txt
4) 6
5) This system performed quite well within its restricted pupose. The system proved to be quite adept at directing the conversation and would also change the webpage it was on depending on the topic while still preserving the chat. In a way it is a sort of page navigation bot - it seems to operate by  asking questions that will allow it to narrow down which page you want to be on. This was clear when it started switching the pages as our questions got more narrow.
6) It seemed to follow human conversational principles pretty well - mainly because it did not try to venture past the paradigm of question and answer. It mainly just had machine-generated questions for humans to answer once they asked an initial question that sent the system down a certain tree of pages.
7) Its ability to navigate pages while talking as well as ask questions in a very clear manner. It was also refreshing after the overwhelming terribleness of the Watson's 'misunderstanding message' to see one that clearly stated that the system did not understand what was going on. 
8) I didn't really see many failures - the system is well contained and restricted so it is pretty well able to either answer a military question or tell you it doesn't understand. In other words, it can't do everything, but it doesn't violate conversation principles and mess up like the systems in a way that confuses users. In another conversation I asked basic statistical questions about the army and those were decently answered - for example the machine could tell me how many people were in the military but couldn't tell me how many guns they had. 
9) Sure. If I need to sign up for the military multiple times I guess. 